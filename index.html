<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Rick O. Gilmore" />
  <title>Video as data &amp; documentation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/reveal.css"/>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="styles.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Video as data &amp; documentation</h1>
    <h2 class="author">Rick O. Gilmore</h2>
    <h3 class="date">2019-08-27 05:17:09</h3>
</section>

<section><section id="preliminaries" class="title-slide slide level1"><h1>Preliminaries</h1></section><section class="slide level2">

<!-- QR code for talk -->
<p><img src="index_files/figure-revealjs/qr-code-1.png" width="768" /></p>
</section><section class="slide level2">

<!-- Funding sources with icons -->
<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/87/NSF_Logo.PNG" height=150px> <img src="https://pbs.twimg.com/profile_images/826768222363975680/8hO9VaFD.jpg" height=150px> </br> <img src="https://sloan.org/storage/app/media/Logos/Sloan-Logo-stacked-black-web.png" height=150px> <img src="http://newsroom.unl.edu/announce/files/file77330.jpg" height=150px/> <img src="https://www.unicef.org.hk/wp-content/uploads/2017/08/Logo-05_Lego-foundation_UNICEF_partnership.jpg" height=150px /> </br> <img src="https://nationalpress.org/wp-content/uploads/2016/04/NIDA-logo-300x300.jpg" height=150px/> <img src="http://bewellva.com/wp-content/uploads/2017/12/NIMH-Logo_14-e1510955490255.jpg" height=150px/> <img src="https://www.jsmf.org/assets/logo-small.png" height=150px/></p>
<aside class="notes">
<p>I thank NSF, NIH, the Alfred P. Sloan Foundation, SRCD, the Lego Foundation, and the James S. McDonnell Foundation for support.</p>
</aside>
</section><section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li>Video as data</li>
<li>Video as documentation</li>
<li>Sharing ethically &amp; securely with Databrary</li>
<li>Accelerating discovery</li>
</ul>
<aside class="notes">
<p>I’ll be talking about video as data and documentation, how video can be shared ethically and securely, and how video sharing will accelerate discovery in the psychological sciences.</p>
</aside>
</section></section>
<section><section id="video-as-data-documentation" class="title-slide slide level1"><h1>Video as data &amp; documentation</h1></section><section class="slide level2">

<p><img src="img/video-as-data-and-documentation.jpg"/></p>
<p><small> <a href="https://www.apa.org/science/about/psa/2017/10/video-data">Adolph, Gilmore, &amp; Kennedy, 2017</a> </small></p>
<!-- Video as data and documentation -->
</section><section id="video-as-data" class="slide level2">
<h2>Video as data</h2>
</section><section class="slide level2">

<p></br> <video width="640" height="480" controls> <source src="https://nyu.databrary.org/slot/9840/-/asset/11192/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="http://doi.org/10.17910/B7PP4W">Frank 2014</a> </small></p>
<!-- Physical abacus -->
<aside class="notes">
<p>Well, let me explain, or better, show. Tell me what’s going on in this short clip?</p>
</aside>
</section><section class="slide level2">

<p></br> <video width="640" height="480" controls> <source src="https://nyu.databrary.org/slot/9840/-/asset/11193/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="http://doi.org/10.17910/B7PP4W">Frank 2014</a> </small></p>
<!-- Mental abacus -->
<aside class="notes">
<p>And how about this one?</p>
<p>That’s right. It’s a mental abacus.</p>
</aside>
</section><section class="slide level2">

<iframe src="http://doi.org/10.17910/B7PP4W" height="600" width="1000">
</iframe>
<p><small> <a href="http://doi.org/10.17910/B7PP4W">Frank 2014</a> </small></p>
<aside class="notes">
<p>And the video let you see the phenomenon directly BEFORE you even read the paper.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/deloache-etal-2004.jpg"/></p>
<p><small> <a href="https://10.1126/science.1093567">DeLoache, Uttal, &amp; Rosengren 2004</a> </small></p>
<aside class="notes">
<p>Another example comes from the work of Judy DeLoache and colleagues on some children’s surprising errors of spatial scale. DeLoache and colleagues observed that children sometimes tried to sit on tiny doll-sized chairs or insert themselves into tiny doll-sized cars after playing and interacting with full-sized chairs or toys.</p>
<p>When they submitted the paper to Science, the editors didn’t believe them.</p>
</aside>
</section><section id="if-a-picture-is-worth-1000-words" class="slide level2">
<h2>If a picture is worth 1,000 words…</h2>
</section><section id="a-video-is-worth" class="slide level2">
<h2>A video is worth…</h2>
</section><section class="slide level2">

<p></br> <video width="640" height="480" controls> <source src="https://nyu.databrary.org/slot/9850/-/asset/11556/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="http://doi.org/10.17910/B7H019">DeLoache 2014</a> </small></p>
</section><section class="slide level2">

<p></br> <video width="640" height="480" controls> <source src="https://nyu.databrary.org/slot/9850/-/asset/11550/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="http://doi.org/10.17910/B7H019">DeLoache 2014</a> </small></p>
</section><section id="a-paper-in-science" class="slide level2">
<h2>…a paper in <em>Science</em></h2>
</section><section id="video" class="slide level2">
<h2>Video…</h2>
<ul>
<li>Captures (&amp; preserves)</li>
<li>Shows (&amp; helps tell…)</li>
<li>Expands the scope of inquiry (e.g., words +)</li>
<li>Provides unparalleled opportunities for reuse</li>
</ul>
<aside class="notes">
<p>Video captures and preserves aspects of behavior that other measures often neglect; it shows what participants do and helps tell the story; it expands the scope of inquiry to include other behaviors; and it provides unparalleled opportunities for reuse.</p>
<p>Video also has unique strengths as research documentation.</p>
</aside>
</section><section id="video-as-documentation" class="slide level2">
<h2>Video as documentation</h2>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.nature.com/news/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg" height=600px> </br> <small> <a href="http://doi.org/10.1038/533452a">Baker, 2016</a> </small></p>
</div>
<aside class="notes">
<p>These are the results.</p>
</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.nature.com/news/polopoly_fs/7.36718.1464174471!/image/reproducibility-graphic-online3.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online3.jpg" width=700px> </br> <small> <a href="http://doi.org/10.1038/533452a">Baker, 2016</a> </small></p>
</div>
<aside class="notes">

</aside>
</section><section class="slide level2">

<div class="centered">
<p><img src="https://www.nature.com/news/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg" width=700px> </br> <small> <a href="http://doi.org/10.1038/533452a">Baker, 2016</a> </small></p>
</div>
<aside class="notes">

</aside>
</section><section class="slide level2">

<p><img src="img/video-can-make-behavioural.jpg" width="1000px" /></p>
<p><small> <a href="https://doi.org/10.1038/s41562-017-0128">Gilmore &amp; Adolph, 2017</a> </small></p>
<aside class="notes">
<p>Karen Adolph and I argue that video recordings of research procedures can make behavioral science more reproducible. Here are some examples.</p>
</aside>
</section><section class="slide level2">

<!-- Caitlyn Fausey accidental and intentional videos -->
<iframe src="http://doi.org/10.17910/b7.873" width="768" height="600">
</iframe>
</section><section class="slide level2">

<iframe src="http://doi.org/10.17910/B7.236" width="768" height="600">
</iframe>
</section><section class="slide level2">

<p></br> <video width="1000" height="240" controls> <source src="https://nyu.databrary.org/slot/11647/0,84928/asset/40653/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="http://doi.org/10.17910/B7.236">Yu 2016</a> </small></p>
<aside class="notes">
<p>Let’s say you’re interested in where children and their parents look to explore the role of joint attention in early word learning.</p>
<p>This video from Databrary shows what the raw video from eyetracking systems used by Yu et al. actually looks like.</p>
</aside>
</section><section class="slide level2">

<iframe src="http://doi.org/10.17910/B7.326" height="600" width="1000">
</iframe>
<p><small> <a href="http://doi.org/10.17910/B7.326">Bahrick, 2017</a> </small></p>
<aside class="notes">
<p>Or maybe you are interested in understanding more Lorraine Bahrick’s multisensory assessment protocol.</p>
</aside>
</section><section class="slide level2">

<p></br> <video width="1000" height="240" controls> <source src="https://nyu.databrary.org/slot/16668/0,140984/asset/72645/download?inline=true" type="video/mp4"> </video> </br></p>
<aside class="notes">
<p>This video on Databrary shows what it looks like from a participant’s perspective.</p>
</aside>
</section><section id="even-audio" class="slide level2">
<h2>Even audio</h2>
<aside class="notes">
<p>Audio recordings can also be shared.</p>
</aside>
</section><section class="slide level2">

<iframe src="http://doi.org/10.17910/b7.339" width="768" height="600">
</iframe>
<p><small> <a href="http://doi.org/10.17910/b7.339">Cole, Gilmore, Perez-Edgar, &amp; Scherf 2017</a> </small></p>
<aside class="notes">
<p>I’m largely a vision scientist, but more generally I’m interested in perceptual and motor development. In collaboration with other colleagues at Penn State, we’ve been exploring behavioral and neural responses to maternal speech in different affective prosodies.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://nyu.databrary.org/slot/19142/-/asset/86229/download?inline=true" height=350px/></p>
<audio controls>
<source src="https://nyu.databrary.org/slot/16956/110000,120032/asset/73386/download?inline=true">
</audio>
<p></br> <audio controls> <source src="https://nyu.databrary.org/slot/16956/0,10032/asset/73350/download?inline=true"> </audio></p>
<p><small> <a href="http://doi.org/10.17910/b7.339">Cole, Gilmore, Perez-Edgar, &amp; Scherf 2017</a> </small></p>
<aside class="notes">
<p>Here are two examples. The full set of recordings are shared on Databrary for the research community to use.</p>
</aside>
</section><section id="shared-video-audio-recordings" class="slide level2">
<h2>Shared video &amp; audio recordings</h2>
<aside class="notes">

</aside>
</section><section class="slide level2">

<ul>
<li>Make research more transparent</li>
<li>Bolster the reproducibility of procedures</li>
<li>Accelerate the adoption of new research techniques</li>
</ul>
</section><section class="slide level2">

<ul>
<li>Strengthen findings</li>
<li>Maximize the return on public investments in research</li>
</ul>
</section></section>
<section><section id="sharing-video-ethically-openly" class="title-slide slide level1"><h1>Sharing video ethically &amp; openly</h1></section><section id="video-must-be-protected" class="slide level2">
<h2>Video must be protected</h2>
<aside class="notes">
<p>Sharing video ethically requires protections.</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Faces, voices</li>
<li>Home interiors</li>
<li>Behaviors that may embarrass participants</li>
</ul>
<aside class="notes">
<p>Video is potentially identifiable. It contains faces and voices. It might contain images of home interiors or capture behaviors that could embarrass participants.</p>
</aside>
</section><section id="open-sharing-advances-discovery" class="slide level2">
<h2>Open sharing advances discovery</h2>
<aside class="notes">
<p>At the same time, open sharing, with limited restrictions on appropriate uses, promises to advance discovery.</p>
<p>How do we strike a balance between the two?</p>
</aside>
</section><section class="slide level2">

<ul>
<li>Citation expected, but</li>
<li>No requirement for co-authorship</li>
<li>No pre-approval of research questions</li>
</ul>
<aside class="notes">
<p>Databrary does not pre-approve research questions nor enforce requirements for co-authorship, but we expect that any researcher using our materials to cite the source.</p>
</aside>
</section><section class="slide level2">

<p><img src="https://nyu.databrary.org/web/images/logo/databrary-nav.svg" height=250px></p>
</section><section id="requires" class="slide level2">
<h2>Requires…</h2>
<ul>
<li>researchers secure participant permission to share</li>
<li>IRB/ethics board approval to share</li>
<li>institutional approval for access</li>
</ul>
<aside class="notes">
<p>Moreover, Databrary requires researchers to secure permission from research participants in order to share their video or audio data. Databrary requires researchers seek ethics board approvals as required by a researcher’s institution. And most importantly, Databrary restricts access to researchers who have been authorized by their institutions to access the site.</p>
</aside>
</section><section id="permission-to-share" class="slide level2">
<h2>Permission to share</h2>
<ul>
<li>Standard language via <a href="https://www.databrary.org/resources/templates.html">templates</a></li>
<li>When to ask &amp; how decided by local ethics boards/IRBs</li>
<li>Sample <a href="https://www.databrary.org/resources/guide/investigators/release/asking/script.html">scripts</a> and <a href="https://www.databrary.org/resources/guide/investigators/release/asking/examples.html">videos</a></li>
</ul>
<aside class="notes">
<p>Databrary has developed standard language for seeking permission to share and provides guidance about when and how to seek ethics board approval. We share sample scripts for talking with participants alongside video exemplars.</p>
<p>Some researchers might be uncertain about how to ask parents or participants for permission to share video or audio, so Databrary includes videos that show how easy it is.</p>
</aside>
</section><section class="slide level2">

<p></br> <video width="800" height="600" controls> <source src="https://www.databrary.org/video/example-video-1.mp4" type="video/mp4"> </video> </br></p>
<aside class="notes">

</aside>
</section><section id="restricting-access" class="slide level2">
<h2>Restricting access</h2>
<ul>
<li>Researchers at institutions</li>
<li>Formalized by an <a href="https://www.databrary.org/resources/agreement.html">institutional agreement</a></li>
<li>Protects participants, researchers, &amp; institutions</li>
</ul>
<aside class="notes">
<p>Only researchers whose institutions have granted explicit access are permitted to share data. Student or staff affiliates an authorized researcher supervises may download or resuse Databrary materials if granted access by their supervisor. A researcher’s institution must sign a formal institutional agreement with NYU, Databrary’s host institution, before a researcher gains full access.</p>
<p>This policy framework protects participants, researchers, and institutions.</p>
</aside>
</section><section id="standardized-levels-of-sharing" class="slide level2">
<h2>Standardized <a href="https://www.databrary.org/resources/guide/investigators/release/release-levels.html">levels of sharing</a></h2>
<aside class="notes">
<p>Databrary has standardized the levels of sharing into categories; every file on the site is tagged with the level of sharing permitted.</p>
</aside>
</section><section class="slide level2">

<!-- <img src="img/sharing-levels.jpg"/> -->
<p><img src="img/sharing-levels.jpg" width="1000px" /></p>
<aside class="notes">
Private files are restricted to the authorized researcher who uploaded them and any other parties they grant access to.
</aside>
</section><section class="slide level2">

<p><img src="img/databrary-map-2019-08-27.jpg" width="1100px" /></p>
<aside class="notes">
<p>As this map indicates, the Databrary policy framework has been agreed to by hundreds of institutions across the globe.</p>
</aside>
</section></section>
<section><section id="accelerating-discovery" class="title-slide slide level1"><h1>Accelerating discovery</h1></section><section id="need" class="slide level2">
<h2>Need</h2>
<ul>
<li>Annotation tools</li>
<li>More (bigger, denser, diverse) data</li>
<li>Platforms for discovery</li>
</ul>
<aside class="notes">
<p>To exploit the power of video to accelerate discovery in behavioral science, we need annotation tools, bigger data, and software tools that go beyond passive data storage but are truly platforms for discovery.</p>
</aside>
</section><section class="slide level2">

<video src="mov/databrary-splash.mp4" data-autoplay loop></video>
</video>
<aside class="notes">
<p>Databrary is one such tool.</p>
</aside>
</section><section class="slide level2">

<iframe src="https://datavyu.org" height="600" width="1000">
</iframe>
<aside class="notes">
<p>Datavyu, a free open-source, annotation tool is another.</p>
</aside>
</section><section class="slide level2">

<p></br> <video width="800" height="600" controls> <source src="https://nyu.databrary.org/slot/27087/0,372193/asset/119877/download?inline=true" type="video/mp4"> </video> </br></p>
<p><small> <a href="https://nyu.databrary.org/volume/444#panel-data">Adolph, Tamis-LeMonda, &amp; Gilmore 2017</a> </small></p>
<aside class="notes">
<p>We’re also creating a large-scale, diverse and rich data set for others to exploit via the Play &amp; Learning Across a Year (PLAY) Project.</p>
</aside>
</section><section class="slide level2">

<ul>
<li><span class="math inline">\(n=900\)</span> infant/mother dyads, <span class="math inline">\(n=300\)</span> 12-, 18-, and 24-month-olds</li>
<li>Demographics, health status, media use, temperament</li>
<li>Modified MB-CDI (interview, video-recorded, English/Spanish item-level equivalents)</li>
<li>Open protocol, video documentation</li>
</ul>
</section><section class="slide level2">

<iframe src="https://play-project.org/" height="600" width="1000">
</iframe>
<aside class="notes">
<p>The entire PLAY project protocol, including videos of procedures, coding definitions, survey items, etc. is openly shared.</p>
</aside>
</section><section id="platforms-for-discovery" class="slide level2">
<h2>Platforms for discovery</h2>
<aside class="notes">
<p>Platforms for discovery require software that interacts with stored and shared data in interesting and useful ways.</p>
<p>We’re making progress on this front, too.</p>
</aside>
</section><section class="slide level2">

<iframe src="https://nyu.databrary.org/volume/8" height="600" width="1000">
</iframe>
<p><small> <a href="http://doi.org/10.17910/B7CC74">Tamis-LeMonda 2013</a> </small></p>
<aside class="notes">
<p>Here’s one of the largest currently shared datasets on Databrary from Catherine Tamis-LeMonda.</p>
<p>Maybe you’re interested in seeing whether it is large and diverse enough for your needs.</p>
</aside>
</section><section class="slide level2">

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">vol_<span class="dv">8</span> &lt;-<span class="st"> </span>databraryapi<span class="op">::</span><span class="kw">download_session_csv</span>(<span class="dt">vol_id =</span> <span class="dv">8</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">xtabs</span>(<span class="dt">formula =</span> <span class="op">~</span><span class="st"> </span>participant.gender <span class="op">+</span><span class="st"> </span>participant.race, <span class="dt">data =</span> vol_<span class="dv">8</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(.)</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th style="text-align: right;">Asian</th>
<th style="text-align: right;">Black or African American</th>
<th style="text-align: right;">Unknown or not reported</th>
<th style="text-align: right;">White</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td>Female</td>
<td>0</td>
<td style="text-align: right;">112</td>
<td style="text-align: right;">341</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">209</td>
</tr>
<tr class="odd">
<td>Male</td>
<td>0</td>
<td style="text-align: right;">111</td>
<td style="text-align: right;">410</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">155</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>Using a few commands in the R programming language, you can securely download the entire demographic dataset from Databrary and plot a tabular summary.</p>
</aside>
</section><section class="slide level2">

<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">race_gender &lt;-<span class="st"> </span>vol_<span class="dv">8</span> <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(participant.gender <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;Male&#39;</span>, <span class="st">&#39;Female&#39;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> participant.race, <span class="dt">fill =</span> participant.race) <span class="op">+</span></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="st">  </span><span class="kw">facet_grid</span>(. <span class="op">~</span><span class="st"> </span>participant.gender) <span class="op">+</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat=</span><span class="st">&quot;count&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">        <span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">        <span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb2-11" data-line-number="11">        <span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</a></code></pre></div>
<aside class="notes">
<p>Or you can create a plot of the data for a report to your collaborators.</p>
</aside>
</section><section class="slide level2">

<p><img src="index_files/figure-revealjs/plot-race-gender-1.png" width="768" /></p>
</section><section class="slide level2">

<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">databraryapi<span class="op">::</span><span class="kw">login_db</span>(<span class="dt">email =</span> <span class="st">&quot;rogilmore@psu.edu&quot;</span>)</a></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">play_session_id &lt;-<span class="st"> </span><span class="dv">26295</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">play_vol_id &lt;-<span class="st"> </span><span class="dv">444</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3"></a>
<a class="sourceLine" id="cb5-4" data-line-number="4">vol_<span class="dv">444</span>_assets &lt;-<span class="st"> </span><span class="kw">list_assets_in_session</span>(<span class="dt">vol_id =</span> play_vol_id, </a>
<a class="sourceLine" id="cb5-5" data-line-number="5">                                         <span class="dt">session_id =</span> play_session_id) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="st">  </span><span class="kw">select</span>(name, asset_type, asset_id)</a></code></pre></div>
<aside class="notes">
<p>Maybe you’re interested in reusing the PLAY project pilot data and want to know what other types of data files are available.</p>
</aside>
</section><section class="slide level2">

<table>
<thead>
<tr class="header">
<th style="text-align: left;">name</th>
<th style="text-align: left;">asset_type</th>
<th style="text-align: right;">asset_id</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">childcare</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">159177</td>
</tr>
<tr class="even">
<td style="text-align: left;">locomotion</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">117092</td>
</tr>
<tr class="odd">
<td style="text-align: left;">child-birth</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">116791</td>
</tr>
<tr class="even">
<td style="text-align: left;">family</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">116790</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sleep</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">116789</td>
</tr>
<tr class="even">
<td style="text-align: left;">language-exposure</td>
<td style="text-align: left;">Comma-separated values</td>
<td style="text-align: right;">116787</td>
</tr>
</tbody>
</table>
</section><section class="slide level2">

<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">lang_exp &lt;-<span class="st"> </span>databraryapi<span class="op">::</span><span class="kw">read_csv_data_as_df</span>(<span class="dt">session_id =</span> play_session_id,</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">                                              <span class="dt">asset_id =</span> <span class="dv">116787</span>)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"></a>
<a class="sourceLine" id="cb6-4" data-line-number="4">lang_exp_plot &lt;-<span class="st"> </span>lang_exp <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(.) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6"><span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> language, <span class="dt">fill =</span> language) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="st">  </span><span class="kw">facet_grid</span>(exposure_context <span class="op">~</span><span class="st"> </span>.) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">stat=</span><span class="st">&#39;count&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-9" data-line-number="9"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb6-10" data-line-number="10">        <span class="dt">strip.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">16</span>),</a>
<a class="sourceLine" id="cb6-11" data-line-number="11">        <span class="dt">axis.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">13</span>),</a>
<a class="sourceLine" id="cb6-12" data-line-number="12">        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a></code></pre></div>
<aside class="notes">
<p>Since you’re a language researcher, you’re especially interested in the types of languages children are exposed to and in what settings.</p>
</aside>
</section><section class="slide level2">

<p><img src="index_files/figure-revealjs/plot-lang-exp-1.png" width="768" /></p>
<aside class="notes">
<p>A few commands later, those data are available to you.</p>
</aside>
</section><section class="slide level2">

<!-- Databrary splash loop -->
<div class="centered">
<video width="900" controls data-autoplay loop>
<source src="mov/databrary-splash.mp4" type="video/mp4">
Your browser does not support the video tag. </video>
</div>
</section><section id="clip-your-audio-or-video" class="slide level2">
<h2>“Clip” your audio or video</h2>
</section><section class="slide level2">

<ul>
<li>Databrary API returns segments given:</li>
<li><code>start_time, end_time</code> in milliseconds</li>
</ul>
<aside class="notes">
<p>The Databrary API returns segments of video or audio gven a start_time and an end_time. So you can reproducibly “clip” a particularly interesting audio or video segment to show your collaborators.</p>
</aside>
</section><section class="slide level2">

<p><img src="img/clip-transcript-example.jpg" height=600px/></p>
</section><section class="slide level2">

<p></br> <video width="800" height="600" controls> <source src="https://nyu.databrary.org/slot/14514/70009864,70048303/asset/61054/download?inline=true" type="video/mp4"> </video> </br></p>
</section><section id="prepare-your-video-other-data-for-sharing" class="slide level2">
<h2>Prepare your video + other data for sharing</h2>
</section><section class="slide level2">

<ul>
<li>Conduct scripted, reproducible visualizations &amp; analyses</li>
</ul>
<aside class="notes">
<p>These scripts will work for ALL other authorized users on Databrary because they call on Databrary itself, not some file on your Box drive.</p>
</aside>
</section><section id="shared-video-data-documentation-will" class="slide level2">
<h2>Shared video data &amp; documentation will</h2>
</section><section class="slide level2">

<ul>
<li>Make the behavioral sciences more robust &amp; reproducible</li>
<li>Accelerate discovery</li>
</ul>
<aside class="notes">
<p>In short, these tools for sharing video as data and documentation will make the behvaioral sciences more robust and reproducible and will accelerate discovery.</p>
</aside>
</section></section>
<section><section id="next-steps" class="title-slide slide level1"><h1>Next steps…</h1></section><section id="register-for-databrary-access" class="slide level2">
<h2>Register for Databrary access</h2>
</section><section class="slide level2">

<p><img src="img/register-databrary.jpg" height=600px/></p>
</section><section id="download-test-and-help-improve-the-databraryapi-and-databrarypy-packages" class="slide level2">
<h2>Download, test, and help improve the <a href="https://github.com/PLAY-behaviorome/databraryapi"><em>databraryapi</em></a> and <a href="https://github.com/PLAY-behaviorome/databrarypy"><em>databrarypy</em></a> packages</h2>
</section><section id="secure-permission-to-share-from-research-participants" class="slide level2">
<h2>Secure permission to share from research participants</h2>
</section><section id="collect-upload-share-video-and-audio-recordings" class="slide level2">
<h2>Collect, upload, &amp; share video and audio recordings</h2>
</section></section>
<section><section id="thank-you" class="title-slide slide level1"><h1>Thank you</h1></section><section class="slide level2">

<video width="800" data-autoplay>
<source src="https://github.com/gilmore-lab/DEVSEC-2018/blob/master/mov/databrary-splash.mp4?raw=true" type="video/mp4">
</video>
<p><small> <a href="mailto:rogilmore@psu.edu" class="email">rogilmore@psu.edu</a></br> <a href="https://gilmore-lab.github.io" class="uri">https://gilmore-lab.github.io</a></br> <a href="https://gilmore-lab.github.io/2019-08-28-apsa/" class="uri">https://gilmore-lab.github.io/2019-08-28-apsa/</a></br> <a href="https://twitter.com/rogilmore">@rogilmore</a> </small></p>
</section></section>
<section><section id="materials" class="title-slide slide level1"><h1>Materials</h1></section><section class="slide level2">

<p><small> This talk was produced on 2019-08-27 in <a href="http://rstudio.com">RStudio</a> version using R Markdown and the reveal.JS framework. The code and materials used to generate the slides may be found at <a href="https://github.com/gilmore-lab/2019-08-28-apsa/" class="uri">https://github.com/gilmore-lab/2019-08-28-apsa/</a>. Information about the R Session that produced the code is as follows:</p>
</section><section class="slide level2">

<pre><code>## R version 3.5.3 (2019-03-11)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Mojave 10.14.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] qrcode_0.1.1            forcats_0.4.0          
##  [3] stringr_1.4.0           dplyr_0.8.1            
##  [5] purrr_0.3.2             readr_1.3.1            
##  [7] tidyr_0.8.3             tibble_2.1.3           
##  [9] ggplot2_3.2.0           tidyverse_1.2.1        
## [11] databraryapi_0.1.6.9001
## 
## loaded via a namespace (and not attached):
##  [1] revealjs_0.9      tidyselect_0.2.5  xfun_0.8         
##  [4] reshape2_1.4.3    haven_2.1.0       lattice_0.20-38  
##  [7] colorspace_1.4-1  generics_0.0.2    htmltools_0.3.6  
## [10] yaml_2.2.0        rlang_0.4.0       R.oo_1.22.0      
## [13] pillar_1.4.1      glue_1.3.1        withr_2.1.2      
## [16] R.utils_2.9.0     modelr_0.1.4      readxl_1.3.1     
## [19] plyr_1.8.4        munsell_0.5.0     gtable_0.3.0     
## [22] cellranger_1.1.0  R.methodsS3_1.7.1 rvest_0.3.4      
## [25] codetools_0.2-16  evaluate_0.14     labeling_0.3     
## [28] knitr_1.23        curl_3.3          highr_0.8        
## [31] broom_0.5.2       Rcpp_1.0.1        scales_1.0.0     
## [34] backports_1.1.4   jsonlite_1.6      hms_0.4.2        
## [37] packrat_0.5.0     digest_0.6.19     stringi_1.4.3    
## [40] keyring_1.1.0     grid_3.5.3        cli_1.1.0        
## [43] tools_3.5.3       magrittr_1.5      lazyeval_0.2.2   
## [46] crayon_1.3.4      pkgconfig_2.0.2   xml2_1.2.0       
## [49] lubridate_1.7.4   assertthat_0.2.1  rmarkdown_1.13   
## [52] httr_1.4.0        rstudioapi_0.10   R6_2.4.0         
## [55] nlme_3.1-140      compiler_3.5.3</code></pre>
</section></section>
    </div>
  </div>

  <script src="libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: true,
        // Enables touch navigation on devices with touch input
        touch: true,
        // Opens links in an iframe preview overlay
        previewLinks: false,
        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
          { src: 'libs/reveal.js-3.3.0.1/plugin/notes/notes.js', async: true },
          { src: 'libs/reveal.js-3.3.0.1/plugin/zoom-js/zoom.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
